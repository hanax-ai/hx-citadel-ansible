# Defects & Backlog Items - October 10, 2025

## üêõ Active Defects

### DEFECT-001: LightRAG JsonDocStatusStorage Not Initialized
**Severity:** HIGH  
**Component:** Component 6 (LightRAG Engine)  
**Status:** Open  
**Discovered:** October 10, 2025 during Component 7 validation  
**Affects:** Knowledge graph insertion functionality

#### Description
LightRAG engine fails to insert chunks into the knowledge graph with error:
```
JsonDocStatusStorage not initialized. Please ensure proper initialization:
  rag = LightRAG(...)
```

#### Impact
- ‚úÖ Workers process chunks successfully
- ‚úÖ Jobs tracked correctly in PostgreSQL/Redis
- ‚úÖ Queue drains properly
- ‚ùå **Chunks not inserted into LightRAG knowledge graph**
- ‚ùå **No entities/relationships extracted**
- ‚ùå **KG queries will return empty results**

#### Root Cause
LightRAG library requires specific initialization sequence for `JsonDocStatusStorage` that is not being followed in `services/lightrag_service.py`.

#### Error Details
```
File: /opt/hx-citadel-shield/orchestrator/services/lightrag_service.py
Function: insert_text()
Error: JsonDocStatusStorage not initialized
Reference: https://github.com/HKUDS/LightRAG#important-initialization-requirements
```

#### Reproduction Steps
1. POST to `/lightrag/ingest-async` with test chunks
2. Workers pick up chunks from Redis Streams
3. Call `lightrag_service.insert_text()`
4. Error thrown, chunk not inserted into KG

#### Logs
```
2025-10-10 03:13:35 - shield-orchestrator.lightrag - INFO - Inserting text into LightRAG (43 chars)...
2025-10-10 03:13:35 - shield-orchestrator.lightrag - ERROR - LightRAG insertion error: JsonDocStatusStorage not initialized
```

#### Investigation Needed
1. Review LightRAG library initialization requirements
2. Check if `working_dir` parameter is correctly set
3. Verify `JsonDocStatusStorage` is initialized before `LightRAG()` constructor
4. Check if storage backend (file-based) has proper permissions
5. Review reference implementation in `tech_kb/shield_mcp_complete/`

#### Proposed Fix
Update `services/lightrag_service.py` initialization:
```python
from lightrag.storage import JsonDocStatusStorage

async def init_lightrag():
    # Initialize storage first
    storage = JsonDocStatusStorage(working_dir=settings.lightrag_working_dir)
    
    # Then initialize LightRAG with storage
    global lightrag
    lightrag = LightRAG(
        working_dir=settings.lightrag_working_dir,
        storage=storage,  # Pass initialized storage
        ...
    )
```

#### Workaround
None - this is a core functionality issue. Workers continue to process but data is not persisted to KG.

#### Priority Justification
- **HIGH**: Core feature broken (knowledge graph insertion)
- **Blocking**: KG queries will fail without data
- **User Impact**: No entity extraction or relationship discovery
- **Business Impact**: Cannot build knowledge graph

#### Assigned To
TBD

#### Related Components
- Component 6: LightRAG Engine
- Component 7: Worker Pool (functioning correctly, reveals the issue)

---

## üìã Backlog Items

### BACKLOG-001: Add LightRAG Health Check Endpoint
**Priority:** MEDIUM  
**Component:** Component 6 (LightRAG Engine)  
**Status:** Proposed

#### Description
Add dedicated health check endpoint for LightRAG engine to verify:
- Storage initialization status
- KG statistics (entity/relationship counts)
- Last successful insertion timestamp

#### Proposed Endpoint
```
GET /lightrag/health
Response:
{
  "status": "healthy" | "degraded" | "error",
  "storage_initialized": true,
  "working_dir": "/path/to/working_dir",
  "entity_count": 1234,
  "relationship_count": 5678,
  "last_insertion": "2025-10-10T03:13:35Z",
  "errors": []
}
```

#### Business Value
- Early detection of storage initialization issues
- Monitoring/alerting capability
- Easier troubleshooting

---

### BACKLOG-002: PostgreSQL SSL Configuration Options
**Priority:** LOW  
**Component:** Component 7 (Database Connection)  
**Status:** Proposed

#### Description
Current implementation disables SSL for all PostgreSQL connections:
```python
"ssl": False  # Disable SSL for local PostgreSQL connections
```

This is appropriate for local/dev environments but may need configuration for production.

#### Proposed Enhancement
Make SSL configurable via environment variable:
```python
"ssl": settings.postgres_ssl_enabled,  # Default: False for local, True for remote
"sslmode": settings.postgres_ssl_mode,  # verify-full, require, etc.
```

#### Environment Variables
```bash
POSTGRES_SSL_ENABLED=false  # Local dev
POSTGRES_SSL_ENABLED=true   # Production
POSTGRES_SSL_MODE=verify-full
POSTGRES_SSL_CERT=/path/to/client.crt
POSTGRES_SSL_KEY=/path/to/client.key
```

#### Business Value
- Security best practices for production
- Compliance requirements
- Flexibility for different deployment environments

---

### BACKLOG-003: Worker Pool Scaling Configuration
**Priority:** MEDIUM  
**Component:** Component 7 (Worker Pool)  
**Status:** Proposed

#### Description
Current worker pool is hardcoded to 4 workers. Consider making this configurable based on:
- CPU cores available
- Memory constraints
- Queue depth
- Processing throughput requirements

#### Proposed Configuration
```yaml
# defaults/main.yml
worker_pool_size: 4  # Current
worker_pool_size_auto: true  # Auto-scale based on CPU cores
worker_pool_min: 2
worker_pool_max: 16
```

#### Implementation
```python
import multiprocessing

pool_size = settings.worker_pool_size
if settings.worker_pool_auto:
    pool_size = min(
        max(multiprocessing.cpu_count() - 1, settings.worker_pool_min),
        settings.worker_pool_max
    )
```

#### Business Value
- Better resource utilization
- Improved throughput for large ingestion jobs
- Flexibility for different server configurations

---

### BACKLOG-004: Event Bus Persistence
**Priority:** LOW  
**Component:** Component 7 (Event Bus)  
**Status:** Proposed

#### Description
Current event bus is in-memory with 100-event circular buffer. Events are lost on:
- Service restart
- Client disconnect/reconnect
- Buffer overflow

#### Proposed Enhancement
Add optional Redis-backed event persistence:
```python
class EventBus:
    def __init__(self, persistence_backend=None):
        self.buffer = deque(maxlen=100)  # In-memory
        self.persistence = persistence_backend  # Optional Redis/PostgreSQL
```

#### Use Cases
- Event replay for debugging
- Audit trail
- Client recovery after disconnect
- Historical event analysis

#### Business Value
- Better observability
- Compliance/audit requirements
- Troubleshooting capability

---

### BACKLOG-005: Job Cleanup Automation
**Priority:** MEDIUM  
**Component:** Component 7 (Job Tracker)  
**Status:** Proposed

#### Description
Current implementation has:
- Redis TTL: 1 hour (automatic cleanup)
- PostgreSQL: No cleanup (infinite retention)

Old completed jobs will accumulate in PostgreSQL over time.

#### Proposed Enhancement
Add automated cleanup job:
```python
async def cleanup_old_jobs():
    """Delete jobs older than retention period"""
    retention_days = settings.job_retention_days  # Default: 30
    cutoff_date = datetime.utcnow() - timedelta(days=retention_days)
    
    async with get_db_session() as session:
        await session.execute(
            delete(JobStatus).where(
                JobStatus.status == "completed",
                JobStatus.completed_at < cutoff_date
            )
        )
```

#### Configuration
```bash
JOB_RETENTION_DAYS=30  # Keep completed jobs for 30 days
JOB_CLEANUP_INTERVAL=86400  # Run cleanup daily
```

#### Business Value
- Database size management
- Performance optimization (smaller tables)
- Cost reduction (storage)

---

### BACKLOG-006: Dead Letter Queue for Failed Tasks
**Priority:** MEDIUM  
**Component:** Component 7 (Worker Pool)  
**Status:** Proposed

#### Description
Current implementation acknowledges failed tasks but doesn't preserve them for investigation or retry.

#### Proposed Enhancement
Add dead letter queue (DLQ) for failed tasks:
```python
# After max retries exceeded
await redis_streams.add_to_dlq(
    queue="shield:ingestion_dlq",
    task_id=task_id,
    error=str(error),
    retry_count=retry_count,
    original_task=task_data
)
```

#### Features
- Preserve failed tasks for investigation
- Manual retry capability
- Error pattern analysis
- Alerting on DLQ depth threshold

#### Business Value
- Data loss prevention
- Better error tracking
- Support/debugging capability

---

## üìä Summary

**Active Defects:** 1 (1 HIGH)  
**Backlog Items:** 6 (2 MEDIUM, 4 LOW)  
**Blocking Issues:** 1 (DEFECT-001)

### Next Actions
1. **URGENT**: Fix DEFECT-001 (LightRAG storage initialization)
2. **HIGH**: Implement BACKLOG-003 (worker pool scaling)
3. **MEDIUM**: Review BACKLOG-005 (job cleanup)
4. **MEDIUM**: Consider BACKLOG-006 (DLQ)

---

**Report Generated:** October 10, 2025 03:15 UTC  
**Last Updated:** October 10, 2025 03:15 UTC  
**Component 7 Status:** Operational (with known LightRAG limitation)  
**Next Review:** After DEFECT-001 fix
