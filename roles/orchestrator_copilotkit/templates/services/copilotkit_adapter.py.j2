"""
CopilotKit Adapter for shield-power-ui
Component 10: Human-in-the-Loop Frontend Integration

Provides CopilotKit-compatible endpoints for:
- State streaming (useCopilotReadable)
- Action execution (useCopilotAction)
- Progress updates
- Workflow integration

Generated by Ansible for {{ ansible_hostname }}
"""

from typing import Dict, Any, AsyncIterator, Optional
import logging
import json
import asyncio
from datetime import datetime

from services.lightrag_service import lightrag_service
from services.job_tracker import job_tracker
from services.workflow_manager import workflow_manager

logger = logging.getLogger("shield-orchestrator.copilotkit")


class CopilotKitAdapter:
    """
    Adapter for CopilotKit integration with shield-power-ui.
    
    Provides human-in-the-loop capabilities:
      - Real-time state streaming for job progress
      - Action execution for user-initiated operations
      - Workflow integration for intelligent processing
      - Knowledge base interaction
    
    Frontend Integration:
      - useCopilotReadable: Subscribe to state updates
      - useCopilotAction: Trigger backend actions
      - SSE streaming: Real-time progress updates
    """
    
    def __init__(self):
        self._initialized = False
        logger.info("CopilotKit adapter created")
    
    async def initialize(self) -> None:
        """Initialize CopilotKit adapter."""
        if self._initialized:
            return
        
        logger.info("ðŸš€ Initializing CopilotKit adapter...")
        self._initialized = True
        logger.info("âœ… CopilotKit adapter initialized")
    
    async def stream_state(self, job_id: str) -> AsyncIterator[str]:
        """
        Stream job state for useCopilotReadable hook.
        
        Yields SSE-formatted state updates at 1-second intervals.
        Automatically completes when job reaches terminal state.
        
        Args:
            job_id: Job identifier to track
            
        Yields:
            str: SSE-formatted state update messages
            
        Example Output:
            data: {"type":"state","data":{"jobId":"abc123","status":"running","progress":45}}
        """
        logger.info(f"Starting state stream for job: {job_id}")
        
        try:
            while True:
                # Get current job progress
                progress = await job_tracker.get_progress(job_id)
                
                if not progress:
                    # Job not found
                    error_update = {
                        "type": "error",
                        "data": {
                            "jobId": job_id,
                            "error": "Job not found",
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    }
                    yield f"data: {json.dumps(error_update)}\n\n"
                    break
                
                # Build state update
                state_update = {
                    "type": "state",
                    "data": {
                        "jobId": job_id,
                        "status": progress.get("status", "unknown"),
                        "progress": progress.get("percent_complete", 0),
                        "chunksProcessed": progress.get("chunks_processed", 0),
                        "chunksTotal": progress.get("chunks_total", 0),
                        "message": progress.get("message", ""),
                        "timestamp": datetime.utcnow().isoformat()
                    }
                }
                
                yield f"data: {json.dumps(state_update)}\n\n"
                
                # Check if job is in terminal state
                if progress.get("status") in ["completed", "failed", "cancelled"]:
                    logger.info(f"Job {job_id} reached terminal state: {progress.get('status')}")
                    break
                
                # Wait before next update
                await asyncio.sleep(1)
        
        except Exception as e:
            logger.error(f"Error streaming state for job {job_id}: {e}")
            error_update = {
                "type": "error",
                "data": {
                    "jobId": job_id,
                    "error": str(e),
                    "timestamp": datetime.utcnow().isoformat()
                }
            }
            yield f"data: {json.dumps(error_update)}\n\n"
    
    async def stream_keepalive(self) -> AsyncIterator[str]:
        """
        Stream keepalive messages for SSE connection.
        
        Sends comment lines every {{ sse_keepalive_interval }} seconds to prevent timeout.
        Used for long-running connections without state updates.
        """
        while True:
            yield f": keepalive {datetime.utcnow().isoformat()}\n\n"
            await asyncio.sleep({{ sse_keepalive_interval }})
    
    async def execute_action(
        self,
        action_name: str,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Execute CopilotKit action from frontend.
        
        Available Actions:
          - search_knowledge: Query the knowledge graph
          - ingest_document: Queue document for ingestion
          - query_workflow: Execute intelligent query workflow
          - get_job_status: Get detailed job information
        
        Args:
            action_name: Name of action to execute
            parameters: Action-specific parameters
            
        Returns:
            Dict containing action result or error
        """
        logger.info(f"Executing CopilotKit action: {action_name}")
        logger.debug(f"Parameters: {parameters}")
        
        try:
            if action_name == "search_knowledge":
                return await self._action_search_knowledge(parameters)
            
            elif action_name == "ingest_document":
                return await self._action_ingest_document(parameters)
            
            elif action_name == "query_workflow":
                return await self._action_query_workflow(parameters)
            
            elif action_name == "get_job_status":
                return await self._action_get_job_status(parameters)
            
            else:
                return {
                    "success": False,
                    "error": f"Unknown action: {action_name}",
                    "available_actions": [
                        "search_knowledge",
                        "ingest_document",
                        "query_workflow",
                        "get_job_status"
                    ]
                }
        
        except Exception as e:
            logger.error(f"Action execution failed: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "action": action_name
            }
    
    async def _action_search_knowledge(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Search knowledge graph action."""
        query = params.get("query", "")
        mode = params.get("mode", "hybrid")  # hybrid, local, global, naive
        
        if not query:
            return {"success": False, "error": "Query parameter required"}
        
        logger.info(f"Searching knowledge: '{query}' (mode: {mode})")
        result = await lightrag_service.query(query, mode=mode)
        
        return {
            "success": True,
            "action": "search_knowledge",
            "query": query,
            "mode": mode,
            "result": result,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def _action_ingest_document(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Ingest document action."""
        url = params.get("url")
        title = params.get("title", "Untitled Document")
        
        if not url:
            return {"success": False, "error": "URL parameter required"}
        
        logger.info(f"Queueing document ingestion: {title} ({url})")
        
        # Create ingestion job
        from services.event_bus import event_bus
        
        job_id = await job_tracker.create_job(
            job_type="ingestion",
            data={"url": url, "title": title}
        )
        
        # Emit ingestion event
        await event_bus.emit("ingestion.queued", {
            "job_id": job_id,
            "url": url,
            "title": title
        })
        
        return {
            "success": True,
            "action": "ingest_document",
            "job_id": job_id,
            "url": url,
            "title": title,
            "status": "queued",
            "stream_url": f"/copilotkit/stream/{job_id}",
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def _action_query_workflow(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Execute query workflow action."""
        query = params.get("query", "")
        mode = params.get("mode", "auto")  # auto, fast, deep
        
        if not query:
            return {"success": False, "error": "Query parameter required"}
        
        logger.info(f"Executing query workflow: '{query}' (mode: {mode})")
        
        # Execute query workflow (Component 9)
        result = await workflow_manager.execute_query_workflow(
            query=query,
            user_id="copilotkit_user",
            session_id=None
        )
        
        return {
            "success": True,
            "action": "query_workflow",
            "query": query,
            "mode": mode,
            "result": result,
            "workflow_id": result.get("workflow_id"),
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def _action_get_job_status(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Get job status action."""
        job_id = params.get("job_id")
        
        if not job_id:
            return {"success": False, "error": "job_id parameter required"}
        
        progress = await job_tracker.get_progress(job_id)
        
        if not progress:
            return {
                "success": False,
                "error": f"Job not found: {job_id}"
            }
        
        return {
            "success": True,
            "action": "get_job_status",
            "job_id": job_id,
            "status": progress,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def shutdown(self) -> None:
        """Shutdown CopilotKit adapter."""
        logger.info("Shutting down CopilotKit adapter...")
        self._initialized = False
        logger.info("âœ… CopilotKit adapter shutdown complete")


# Global adapter instance
copilotkit_adapter = CopilotKitAdapter()
